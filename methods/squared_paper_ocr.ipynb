{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR on squared paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pytesseract\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Path to tesseract executable (in case it isn't in your PATH)\n",
    "try:\n",
    "    subprocess.call([\"tesseract\"])\n",
    "except FileNotFoundError:\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "PARENT_DIR = os.path.dirname(os.path.dirname(os.path.realpath(\"FILEPATH\")))\n",
    "image_name = \"012.jpg\"\n",
    "image = cv2.imread(os.path.join(PARENT_DIR, \"images\", image_name), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Tesseract OCR before processing\n",
    "print(\"Before processing:\")\n",
    "print(\"\\\"\\n\" + pytesseract.image_to_string(image) + \"\\n\\\"\")\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# for image 011.jpg, use a different thresholding method\n",
    "if image_name == \"011.jpg\":\n",
    "    thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "opening = cv2.morphologyEx(cv2.medianBlur(thresh, 7), cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))\n",
    "# opening = cv2.erode(opening, np.ones((5,5),np.uint8), iterations=1)\n",
    "\n",
    "# Tesseract OCR after processing\n",
    "print(\"After processing:\")\n",
    "print(\"\\\"\\n\" + pytesseract.image_to_string(opening) + \"\\n\\\"\")\n",
    "\n",
    "bitwise_not = cv2.bitwise_not(opening)\n",
    "\n",
    "plt.imshow(bitwise_not, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template from inside the image\n",
    "top_left = image[:int(image.shape[0] / 5), :int(image.shape[1] / 5)]\n",
    "template = cv2.threshold(top_left, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "plt.imshow(template, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan the whole template, counting the consecutive black pixels and the number of black strings (consecutive black pixels)\n",
    "black_strings = 0\n",
    "black_pixels = 0\n",
    "previous = 0\n",
    "for i in range(template.shape[0]):\n",
    "    for j in range(template.shape[1]):\n",
    "        if template[i][j] == 0:\n",
    "            black_pixels += 1\n",
    "            if previous == 0:\n",
    "                black_strings += 1\n",
    "                previous = 1\n",
    "        else:\n",
    "            previous = 0\n",
    "print(\"Black strings: \", black_strings)\n",
    "print(\"Black pixels: \", black_pixels)\n",
    "\n",
    "scaling = 0.8  # The line width might be less thick than the value found\n",
    "line_width = int((black_pixels / black_strings) * scaling)\n",
    "print(\"Average black string length: \", line_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structure element for extracting horizontal lines through morphology operations\n",
    "horizontal_structure = cv2.getStructuringElement(cv2.MORPH_RECT, (line_width, 1))\n",
    "\n",
    "# Apply morphology operations to extract horizontal lines\n",
    "horizontal = cv2.morphologyEx(bitwise_not, cv2.MORPH_OPEN, horizontal_structure, iterations=2)\n",
    "plt.imshow(horizontal, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in horizontal lines only the ones that have a length greater than 8% of the image width\n",
    "horizontal = cv2.erode(horizontal, np.ones((1, int(image.shape[1] * 0.08)), np.uint8), iterations=1)\n",
    "plt.imshow(horizontal, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structure element for extracting vertical lines through morphology operations\n",
    "vertical_structure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, line_width))\n",
    "\n",
    "# Apply morphology operations to extract vertical lines\n",
    "vertical = cv2.morphologyEx(bitwise_not, cv2.MORPH_OPEN, vertical_structure, iterations=2)\n",
    "plt.imshow(vertical, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in vertical lines only the ones that have a length greater than 8% of the image height\n",
    "vertical = cv2.erode(vertical, np.ones((int(image.shape[0] * 0.08), 1), np.uint8), iterations=1)\n",
    "plt.imshow(vertical, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two images to extract the grid lines\n",
    "grid = cv2.add(horizontal, vertical)\n",
    "plt.imshow(grid, cmap='gray')\n",
    "\n",
    "# Invert the grid image to get the grid lines\n",
    "grid = cv2.bitwise_not(grid)\n",
    "\n",
    "# Erode the grid lines to make them thicker\n",
    "grid = cv2.erode(grid, np.ones((3, 3), np.uint8), iterations=2)\n",
    "\n",
    "plt.imshow(grid, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove grid lines from the image\n",
    "cleaned = cv2.bitwise_and(bitwise_not, grid)\n",
    "\n",
    "# Invert the image to get the text in black\n",
    "#cleaned = cv2.bitwise_not(cleaned)\n",
    "\n",
    "cleaned = cv2.GaussianBlur(cleaned, (5, 5), 0)\n",
    "# Opening to remove noise\n",
    "cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, np.ones((2, 2), np.uint8), iterations=2)\n",
    "\n",
    "dilatation_size = 1\n",
    "dilation_shape = cv2.MORPH_RECT\n",
    "element = cv2.getStructuringElement(dilation_shape, (2 * dilatation_size + 1, 2 * dilatation_size + 1),\n",
    "                                    (dilatation_size, dilatation_size))\n",
    "dilated = cv2.dilate(cleaned, element)\n",
    "\n",
    "# Tesseract OCR after processing\n",
    "print(\"After processing:\")\n",
    "print(\"\\\"\\n\" + pytesseract.image_to_string(dilated) + \"\\n\\\"\")\n",
    "\n",
    "plt.imshow(dilated, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
